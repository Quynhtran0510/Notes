{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPERVISED LEARNING - CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] ==\"male\"\n",
    "X = df[[\"Pclass\", \"male\", \"Age\", \"Siblings/Spouses\",\"Parents/Children\", \"Fare\"]].values\n",
    "y = df['Survived'].values\n",
    "# print(X) # it's standard practice to call 2nd array of X and 1d array of Y\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logictic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model using Fare and Age columns\n",
    "X = df[['Fare', \"Age\"]].values\n",
    "y = df['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the fit method to build the model\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01615949 -0.01549065]] [-0.51037152]\n"
     ]
    }
   ],
   "source": [
    "# coef_ and intercept_ attributes\n",
    "print(model.coef_, model.intercept_)\n",
    "# it means 0 = 0.01615949x - 0.01549065y - 0.51037152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model using all columns\n",
    "X = df[[\"Pclass\", \"male\", \"Age\", \"Siblings/Spouses\",\"Parents/Children\", \"Fare\"]].values\n",
    "y = df['Survived'].values\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)\n",
    "#  make predictions for the first 5 rows:\n",
    "model.predict((X[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# target array:\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, True, 22.0, 1, 0, 7.25], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 1 passenger in the datasets:\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# model prediction:\n",
    "print(model.predict([[3, True, 22.0, 1, 0, 7.25]]))\n",
    "# target array:\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8049605411499436"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score: counting the number of datapoints the model predicts correctly\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8049605411499436\n",
      "Precision:  0.7734627831715211\n",
      "Recall:  0.6988304093567251\n",
      "f1 score:  0.7342549923195083\n"
     ]
    }
   ],
   "source": [
    "# Accuracy, Precision, Recal and F1 score\n",
    "y_pred = model.predict(X)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Accuracy: \", accuracy_score(y,y_pred))\n",
    "print(\"Precision: \", precision_score(y,y_pred))\n",
    "print(\"Recall: \", recall_score(y, y_pred))\n",
    "print(\"f1 score: \", f1_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[475,  70],\n",
       "       [103, 239]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, y_pred)\n",
    "# the result means 475 actual negative - pred negative, 70 actual neg - pred- neg\n",
    "# 103 actual pos - pred pos, 239 actual pos - pred pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6988304093567251"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sensitivity and Specificity\n",
    "from sklearn.metrics import recall_score\n",
    "sensitivity_score = recall_score\n",
    "sensitivity_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.82179931, 0.77346278]),\n",
       " array([0.87155963, 0.69883041]),\n",
       " array([0.84594835, 0.73425499]),\n",
       " array([545, 342], dtype=int64))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8459483526268923\n"
     ]
    }
   ],
   "source": [
    "specificity_score = precision_recall_fscore_support(y, y_pred)[2][0]\n",
    "print(specificity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict proba:\n",
      "[0.32676771 0.67323229]\n"
     ]
    }
   ],
   "source": [
    "# Foundation for the ROC curve:\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"predict proba:\")\n",
    "print(model.predict_proba(X_test)[0])\n",
    "# The first value is the probability that the datapoint is in the 0 class (didn’t survive)\n",
    "# the second is the probability that the datapoint is in the 1 class (survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 AUC score: 0.8104359885585508\n",
      "model 1 AUC score: 0.783435901880905\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation: the ROC curve\n",
    "# Area Under the Curve (AUC score): the higher the AUC score, the better model\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred_proba1 = model1.predict_proba(X_test)\n",
    "print(\"model 1 AUC score:\", roc_auc_score(y_test, y_pred_proba1[:, 1]))\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train[:, 0:2], y_train)\n",
    "y_pred_proba2 = model2.predict_proba(X_test[:, 0:2])\n",
    "print(\"model 1 AUC score:\", roc_auc_score(y_test, y_pred_proba2[:, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set indices: [1 2 4 5]\n",
      "test set indices: [0 3]\n",
      "X_train\n",
      "[[38.     71.2833]\n",
      " [26.      7.925 ]\n",
      " [35.      8.05  ]\n",
      " [27.      8.4583]]\n",
      "y_train [1 1 0 0]\n",
      "X_test\n",
      "[[22.    7.25]\n",
      " [35.   53.1 ]]\n",
      "y_test [0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "X = df[['Age', 'Fare']].values[:6]\n",
    "y = df['Survived'].values[:6]\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True) # 3 Sets of data, in each set auto split 80 train - 20 test data\n",
    "\n",
    "splits = list(kf.split(X))\n",
    "first_split = splits[0]\n",
    "train_indices, test_indices = first_split\n",
    "print(\"training set indices:\", train_indices)\n",
    "print(\"test set indices:\", test_indices)\n",
    "\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "print(\"y_train\", y_train)\n",
    "print(\"X_test\")\n",
    "print(X_test)\n",
    "print(\"y_test\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7640449438202247, 0.8258426966292135, 0.807909604519774, 0.8022598870056498, 0.8022598870056498]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thuyq\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "scores = []\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8004634037961024\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with all features\n",
      "accuracy: 0.8049196978353331\n",
      "precision: 0.7760626261779253\n",
      "recall: 0.6982311403807198\n",
      "f1 score: 0.7331856256966469\n",
      "\n",
      "Logistic Regression with Pclass, Sex & Age features\n",
      "accuracy: 0.7891576207706469\n",
      "precision: 0.7425594780823722\n",
      "recall: 0.6887467407450838\n",
      "f1 score: 0.7140755236399094\n",
      "\n",
      "Logistic Regression with Fare & Age features\n",
      "accuracy: 0.6583761823144798\n",
      "precision: 0.6681883116883116\n",
      "recall: 0.2427785546338756\n",
      "f1 score: 0.35363627400894476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X1 = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "X2 = df[['Pclass', 'male', 'Age']].values\n",
    "X3 = df[['Fare', 'Age']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "def score_model(X, y, kf):\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "    print(\"accuracy:\", np.mean(accuracy_scores))\n",
    "    print(\"precision:\", np.mean(precision_scores))\n",
    "    print(\"recall:\", np.mean(recall_scores))\n",
    "    print(\"f1 score:\", np.mean(f1_scores))\n",
    "\n",
    "print(\"Logistic Regression with all features\")\n",
    "score_model(X1, y, kf)\n",
    "print()\n",
    "print(\"Logistic Regression with Pclass, Sex & Age features\")\n",
    "score_model(X2, y, kf)\n",
    "print()\n",
    "print(\"Logistic Regression with Fare & Age features\")\n",
    "score_model(X3, y, kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we’ve made a choice of a best model, we build a single final model using all of the data.\n",
    "model = LogisticRegression()\n",
    "model.fit(X1, y)\n",
    "model.predict([[3, False, 25, 0, 1, 2]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with breast cancer data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_data = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer_data['data'], columns = cancer_data['feature_names'])\n",
    "df['target'] = cancer_data['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thuyq\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[cancer_data.feature_names].values\n",
    "y = df['target'].values\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convergence warning.\n",
    "model = LogisticRegression(solver = \"liblinear\")\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9595782073813708"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] ==\"male\"\n",
    "X = df[[\"Pclass\", \"male\", \"Age\", \"Siblings/Spouses\",\"Parents/Children\", \"Fare\"]].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "model= DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 22)\n",
    "model.fit(X_train, y_train)\n",
    "model.predict([[3, True, 22, 1, 0, 7.25]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini vs Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - gini\n",
      "accuracy: 0.7789627372563955\n",
      "precision: 0.7046168092922365\n",
      "recall: 0.7292546883856181\n",
      "Decision Tree - entropy\n",
      "accuracy: 0.78027677267822\n",
      "precision: 0.7239637904468413\n",
      "recall: 0.7015622580173935\n"
     ]
    }
   ],
   "source": [
    "# The default impurity criterion in scikit-learn’s Decision Tree algorithm is the Gini Impurity.\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for criterion in ['gini', 'entropy']:\n",
    "    print(\"Decision Tree - {}\".format(criterion))\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        dt = DecisionTreeClassifier(criterion=criterion)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred = dt.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "    print(\"accuracy:\", np.mean(accuracy))\n",
    "    print(\"precision:\", np.mean(precision))\n",
    "    print(\"recall:\", np.mean(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree.png'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "feature_names = ['Pclass', 'male']\n",
    "X = df[feature_names].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X, y)\n",
    "\n",
    "dot_file = export_graphviz(dt, feature_names=feature_names)\n",
    "graph = graphviz.Source(dot_file)\n",
    "graph.render(filename='tree', format='png', cleanup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-pruning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth parameter to limit the number of steps the tree can have between the root node and the leaf nodes.\n",
    "# min_samples_leaf parameter to tell the model to stop building the tree early if the number of datapoints in a leaf will be below a threshold.\n",
    "# max_leaf_nodes to set a limit on the number of leaf nodes in the tree.\n",
    "dt = DecisionTreeClassifier(max_depth = 3, min_samples_leaf= 2, max_leaf_nodes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'max_depth': 15, 'max_leaf_nodes': 35, 'min_samples_leaf': 1}\n",
      "best score: 0.7709600688632559\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 15, 25],\n",
    "    'min_samples_leaf': [1, 3],\n",
    "    'max_leaf_nodes': [10, 20, 35, 50]}\n",
    "dt = DecisionTreeClassifier()\n",
    "gs = GridSearchCV(dt, param_grid, scoring='f1', cv=5)\n",
    "gs.fit(X, y)\n",
    "print(\"best params:\", gs.best_params_)\n",
    "print(\"best score:\", gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest: a model built with multiple trees\n",
    "# Bootstrapped sample is a random sample of datapoints where we randomly select with replacement datapoints from our original dataset to create a dataset of the same size.\n",
    "# Bootstrap Aggregation (or Bagging) creates an ensemble from multiple models built on bootstrapped samples.\n",
    "# Decorrelating the trees:add some restrictions to the model when building each decision tree so the trees have more variation.\n",
    "# We bag these decision trees, we get a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [1]\n",
      "true value: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
    "df['target'] = cancer_data['target']\n",
    "\n",
    "X = df[cancer_data.feature_names].values\n",
    "y = df['target'].values\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 101)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "first_row = X_test[0]\n",
    "print(\"prediction:\", rf.predict([first_row]))\n",
    "print(\"true value:\", y_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest accuracy: 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "# use the score method to calculate the accuracy over the whole test set\n",
    "print(\"random forest accuracy:\", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree accuracy: 0.916083916083916\n"
     ]
    }
   ],
   "source": [
    "# compare to the Decision Tree model\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"decision tree accuracy:\", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92974693, 0.91212545, 0.93850334, 0.9279615 , 0.9437665 ,\n",
       "       0.94727527, 0.95437044, 0.94378202, 0.95255395, 0.95783263,\n",
       "       0.95960255, 0.95783263, 0.94904518, 0.95784816, 0.95256948,\n",
       "       0.95083062, 0.96840553, 0.95253843, 0.95783263, 0.9648657 ,\n",
       "       0.96489676, 0.95607825, 0.96135693, 0.96134141, 0.95609377,\n",
       "       0.95607825, 0.95255395, 0.95783263, 0.95609377, 0.95786369,\n",
       "       0.95433939, 0.95433939, 0.95609377, 0.95960255, 0.95958702,\n",
       "       0.95255395, 0.96311132, 0.96135693, 0.95607825, 0.95781711,\n",
       "       0.96135693, 0.95607825, 0.96311132, 0.95609377, 0.95960255,\n",
       "       0.96488123, 0.95783263, 0.96309579, 0.95783263, 0.95958702,\n",
       "       0.95784816, 0.96309579, 0.95609377, 0.95609377, 0.96137246,\n",
       "       0.95960255, 0.95960255, 0.95960255, 0.97014439, 0.96314237,\n",
       "       0.95432386, 0.9648657 , 0.96488123, 0.95784816, 0.95958702,\n",
       "       0.95784816, 0.95432386, 0.96311132, 0.95960255, 0.96308027,\n",
       "       0.96135693, 0.95958702, 0.95958702, 0.96311132, 0.95607825,\n",
       "       0.95960255, 0.96135693, 0.96312684, 0.95784816, 0.952585  ,\n",
       "       0.96309579, 0.96135693, 0.96137246, 0.95783263, 0.96485018,\n",
       "       0.95784816, 0.95958702, 0.97012886, 0.95960255, 0.96312684,\n",
       "       0.95432386, 0.95961807, 0.95783263, 0.96135693, 0.96489676,\n",
       "       0.95960255, 0.96311132, 0.95784816, 0.95958702, 0.96839   ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elbow Graph is a model that optimizes performance without adding unnecessary complexity\n",
    "n_estimators = list(range(1, 101))\n",
    "param_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "gs = GridSearchCV(rf, param_grid, cv=5)\n",
    "gs.fit(X, y)\n",
    "n_estimators = list(range(1, 101))\n",
    "param_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "gs = GridSearchCV(rf, param_grid, cv=5)\n",
    "gs.fit(X, y)\n",
    "scores = gs.cv_results_['mean_test_score']\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use matplotlib to graph the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = gs.cv_results_['mean_test_score']\n",
    "plt.plot(n_estimators, scores)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0.9, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we look at this graph, we see that around 10 trees the graph levels out. The best model occurred at n_estimators=33 and n_estimators=64, but given how volatile it is, that was probably due to random chance. We should choose about 10 to be our number of estimators, because we want the minimum number of estimators that still yield maximum performance\n",
    "# Build random forest model with the optimal number of trees\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst radius            0.309701\n",
      "mean concave points     0.183126\n",
      "worst concave points    0.115641\n",
      "mean perimeter          0.064119\n",
      "mean radius             0.058742\n",
      "worst concavity         0.050951\n",
      "radius error            0.049103\n",
      "mean texture            0.017197\n",
      "worst area              0.016512\n",
      "mean concavity          0.014696\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# which subset of features should we use? This is a matter of feature selection.\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "cancer_data = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
    "df['target'] = cancer_data['target']\n",
    "\n",
    "X = df[cancer_data.feature_names].values\n",
    "y = df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101)\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=111)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "ft_imp = pd.Series(rf.feature_importances_, index=cancer_data.feature_names).sort_values(ascending=False)\n",
    "print(ft_imp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "# New model on selected features\n",
    "# In our dataset, we happen to notice that features with \"worst\" seem to have higher importances. As a result we are going to build a new model with the selected features and see if it improves accuracy.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
    "df['target'] = cancer_data['target']\n",
    "\n",
    "X = df[cancer_data.feature_names].values\n",
    "y = df['target'].values\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=111)\n",
    "\n",
    "worst_cols = [col for col in df.columns if 'worst' in col]\n",
    "X_worst = df[worst_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_worst, y, random_state=101)\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
